import os
import logging
import httpx
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
APP_ENV = os.getenv("APP_ENV", "dev").lower()

# ë¡œê±° ì„¤ì • (ìš´ì˜ í™˜ê²½ì—ì„œë§Œ)
if APP_ENV == "prod":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler("/var/log/fastapi/app.log"),
            logging.StreamHandler()
        ]
    )
    log = logging.getLogger(__name__)
else:
    log = None  # ê°œë°œ í™˜ê²½ì—ì„œëŠ” print() ì‚¬ìš©

# ======================================================
# ë¹„ë™ê¸° GPT ì±„ì  í•¨ìˆ˜
# ======================================================
async def grade_text(client: httpx.AsyncClient, student_text: str, criteria: str):
    """
    ìˆ˜í–‰í‰ê°€ ìë™ ì±„ì  â€” ë¬¸ë§¥ ë¶„ì„ ì¤‘ì‹¬ (ë¹„ë™ê¸° ë²„ì „)
    """
    instruction = """
# ì—­í• 
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ë…¼ìˆ  êµì‚¬ì´ì ìˆ˜í–‰í‰ê°€ ì±„ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” í•™ìƒì˜ ë‹µì•ˆì„ ë¬¸ë²•ì ìœ¼ë¡œ ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ì‹œ ì“°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,
ë¬¸ë§¥ì´ ë‹¤ì†Œ ë’¤ì„ì—¬ ìˆë”ë¼ë„ ìŠ¤ìŠ¤ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ë‚´ìš©ì„ ì´í•´í•˜ê³ ,
êµì‚¬ì˜ ì±„ì  ê¸°ì¤€ì— ë”°ë¼ ê³µì •í•˜ê²Œ ì ìˆ˜ì™€ ì´ìœ ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì‚¬í•­
- í•™ìƒì˜ ê¸€ì„ ìˆ˜ì •, ìš”ì•½, ì¬ì‘ì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¬¸ì¥ì´ ë’¤ì£½ë°•ì£½ì´ë”ë¼ë„ ìŠ¤ìŠ¤ë¡œ ë¬¸ë§¥ì„ í•´ì„í•˜ì—¬ ì˜ë¯¸ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
- ì ìˆ˜ëŠ” 10ì  ë§Œì  ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•©ë‹ˆë‹¤.
- ì¶œë ¥ì€ ì˜¤ì§ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
ì ìˆ˜: 8/10
ì´ìœ : í•™ìƒì€ ~~ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ì œì‹œí–ˆìœ¼ë‚˜ ~~ ë¶€ë¶„ì´ ë¶€ì¡±í•¨.

# ì—…ë¬´ ì²˜ë¦¬ ìˆœì„œ
1. í•™ìƒì˜ ë‹µì•ˆì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ë° ë…¼ë¦¬ì ìœ¼ë¡œ ì£¼ì œ íŒŒì•…
2. ë‚´ìš©ì„ í•œ ë²ˆ ë” ê²€í† í•˜ê³  ìˆ˜í–‰í‰ê°€ ì±„ì  ê¸°ì¤€ê³¼ ë¹„êµ
3. ìˆ˜í–‰í‰ê°€ ì±„ì  ê¸°ì¤€ì— ì˜ê±°í•˜ì—¬ ì ìˆ˜ ë„ì¶œ
4. ë„ì¶œëœ ì ìˆ˜ì— ëŒ€í•œ ì´ìœ  ì‘ì„±
5. ì¶œë ¥ í˜•íƒœ: ì ìˆ˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ë©° ì´í›„ ì´ìœ ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
"""

    grading_prompt = f"""
[ì±„ì  ê¸°ì¤€]
{criteria}

[í•™ìƒ ë‹µì•ˆ]
{student_text}

ìš”ì²­ì‚¬í•­:
- í•™ìƒ ê¸€ì˜ ë…¼ë¦¬ íë¦„ì´ ë‹¤ì†Œ ë’¤ì„ì—¬ ìˆë”ë¼ë„ ì˜ë¯¸ë¥¼ íŒŒì•…í•´ ì±„ì 
- í•™ìƒì˜ ê¸€ì„ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜ ì¬ì‘ì„±í•˜ì§€ ë§ ê²ƒ
- ì ìˆ˜ì™€ ì´ìœ ë§Œ ì¶œë ¥í•  ê²ƒ
"""

    full_prompt = instruction.strip() + "\n\n" + grading_prompt.strip()
    token_estimate = len(full_prompt) // 4

    # ë¡œê·¸ ì¶œë ¥
    if APP_ENV == "prod":
        log.info(f"ğŸ” ì˜ˆìƒ í† í° ìˆ˜: ì•½ {token_estimate}ê°œ")
    else:
        print(f"ğŸ” ì˜ˆìƒ í† í° ìˆ˜: ì•½ {token_estimate}ê°œ")

    # ë¹„ë™ê¸° HTTP ìš”ì²­ìœ¼ë¡œ OpenAI API í˜¸ì¶œ
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": full_prompt}],
        "max_tokens": 200,
    }

    try:
        res = await client.post(url, headers=headers, json=payload)
        res.raise_for_status()
    except httpx.HTTPError as e:
        if APP_ENV == "prod":
            log.error(f"âŒ GPT API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        else:
            print(f"âŒ GPT API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

    data = res.json()
    result = data["choices"][0]["message"]["content"].strip()

    if APP_ENV == "prod":
        log.info("âœ… GPT ì±„ì  ì™„ë£Œ")
    else:
        print("âœ… GPT ì±„ì  ì™„ë£Œ")

    return result
